{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# al_01_introduction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you're on Colab or Kaggle\n",
    "# !git clone https://github.com/nlp-with-transformers/notebooks.git\n",
    "# %cd notebooks\n",
    "# from install import *\n",
    "# install_requirements()\n",
    "\n",
    "# pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment\n",
    "```\n",
    "# conda create -n nlp_arvid python=3.10 pytorch torchvision torchaudio pytorch-cuda=11.8 pytorch-scatter -c pytorch -c nvidia -c pyg\n",
    "# conda activate nlp_arvid\n",
    "# conda install notebook ipykernel ipywidgets git-lfs libsndfile -c conda-forge\n",
    "# pip install -r requirements.txt\n",
    "# pip install tensorrt\n",
    "# pip install astor\n",
    "\n",
    "\n",
    "# conda deactivate\n",
    "# conda env remove -n nlp_arvid\n",
    "#  ...\n",
    "#   - cudatoolkit=11.8\n",
    "# ...\n",
    "# conda env update-f environment_nlp_arvid.yml\n",
    "# canda activate nlp_arvid\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA RTX A5000 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transformers v4.16.2\n",
      "Using datasets v2.11.0\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "'plotting.mplstyle' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/nlp_arvid/lib/python3.10/site-packages/matplotlib/style/core.py:166\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     style \u001b[39m=\u001b[39m _rc_params_in_file(style)\n\u001b[1;32m    167\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIOError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_arvid/lib/python3.10/site-packages/matplotlib/__init__.py:850\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[0;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[1;32m    849\u001b[0m rc_temp \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 850\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_or_url(fname) \u001b[39mas\u001b[39;00m fd:\n\u001b[1;32m    851\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_arvid/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_arvid/lib/python3.10/site-packages/matplotlib/__init__.py:827\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    826\u001b[0m fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(fname)\n\u001b[0;32m--> 827\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(fname, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    828\u001b[0m     \u001b[39myield\u001b[39;00m f\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plotting.mplstyle'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#hide\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mal_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m setup_chapter()\n",
      "File \u001b[0;32m~/GitHub/nlp-with-transformers/al-nlp-transformers/al_utils.py:55\u001b[0m, in \u001b[0;36msetup_chapter\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     huggingface_hub\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mset_verbosity_error()\n\u001b[1;32m     54\u001b[0m \u001b[39m# Use O'Reilly style for plots\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m set_plot_style()\n",
      "File \u001b[0;32m~/GitHub/nlp-with-transformers/al-nlp-transformers/al_utils.py:28\u001b[0m, in \u001b[0;36mset_plot_style\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m install_mpl_fonts()\n\u001b[1;32m     27\u001b[0m set_matplotlib_formats(\u001b[39m\"\u001b[39m\u001b[39mpdf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m plt\u001b[39m.\u001b[39;49mstyle\u001b[39m.\u001b[39;49muse(\u001b[39m\"\u001b[39;49m\u001b[39mplotting.mplstyle\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     29\u001b[0m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m\"\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msetLevel(level\u001b[39m=\u001b[39mlogging\u001b[39m.\u001b[39mERROR)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp_arvid/lib/python3.10/site-packages/matplotlib/style/core.py:168\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    166\u001b[0m         style \u001b[39m=\u001b[39m _rc_params_in_file(style)\n\u001b[1;32m    167\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIOError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 168\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    169\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstyle\u001b[39m!r}\u001b[39;00m\u001b[39m is not a valid package style, path of style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfile, URL of style file, or library style name (library \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstyles are listed in `style.available`)\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    172\u001b[0m filtered \u001b[39m=\u001b[39m {}\n\u001b[1;32m    173\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m style:  \u001b[39m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: 'plotting.mplstyle' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from al_utils import *\n",
    "setup_chapter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"transformer-timeline\" caption=\"The transformers timeline\" src=\"images/chapter01_timeline.png\" id=\"transformer-timeline\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Encoder-Decoder Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"rnn\" caption=\"Unrolling an RNN in time.\" src=\"images/chapter01_rnn.png\" id=\"rnn\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"enc-dec\" caption=\"Encoder-decoder architecture with a pair of RNNs. In general, there are many more recurrent layers than those shown.\" src=\"images/chapter01_enc-dec.png\" id=\"enc-dec\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"enc-dec-attn\" caption=\"Encoder-decoder architecture with an attention mechanism for a pair of RNNs.\" src=\"images/chapter01_enc-dec-attn.png\" id=\"enc-dec-attn\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"attention-alignment\" width=\"500\" caption=\"RNN encoder-decoder alignment of words in English and the generated translation in French (courtesy of Dzmitry Bahdanau).\" src=\"images/chapter02_attention-alignment.png\" id=\"attention-alignment\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"transformer-self-attn\" caption=\"Encoder-decoder architecture of the original Transformer.\" src=\"images/chapter01_self-attention.png\" id=\"transformer-self-attn\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"transfer-learning\" caption=\"Comparison of traditional supervised learning (left) and transfer learning (right).\" src=\"images/chapter01_transfer-learning.png\" id=\"transfer-learning\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"ulmfit\" width=\"500\" caption=\"The ULMFiT process (courtesy of Jeremy Howard).\" src=\"images/chapter01_ulmfit.png\" id=\"ulmfit\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face Transformers: Bridging the Gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Tour of Transformer Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\n",
    "from your online store in Germany. Unfortunately, when I opened the package, \\\n",
    "I discovered to my horror that I had been sent an action figure of Megatron \\\n",
    "instead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\n",
    "dilemma. To resolve the issue, I demand an exchange of Megatron for the \\\n",
    "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \\\n",
    "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 03:41:10.730456: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-03 03:41:10.758951: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-03 03:41:11.183326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.901546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.901546"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.879010</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.990859</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>Germany</td>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.556570</td>\n",
       "      <td>Mega</td>\n",
       "      <td>208</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.590255</td>\n",
       "      <td>##tron</td>\n",
       "      <td>212</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.669692</td>\n",
       "      <td>Decept</td>\n",
       "      <td>253</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.498350</td>\n",
       "      <td>##icons</td>\n",
       "      <td>259</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.775362</td>\n",
       "      <td>Megatron</td>\n",
       "      <td>350</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.987854</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>367</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.812096</td>\n",
       "      <td>Bumblebee</td>\n",
       "      <td>502</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score           word  start  end\n",
       "0          ORG  0.879010         Amazon      5   11\n",
       "1         MISC  0.990859  Optimus Prime     36   49\n",
       "2          LOC  0.999755        Germany     90   97\n",
       "3         MISC  0.556570           Mega    208  212\n",
       "4          PER  0.590255         ##tron    212  216\n",
       "5          ORG  0.669692         Decept    253  259\n",
       "6         MISC  0.498350        ##icons    259  264\n",
       "7         MISC  0.775362       Megatron    350  358\n",
       "8         MISC  0.987854  Optimus Prime    367  380\n",
       "9          PER  0.812096      Bumblebee    502  511"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "outputs = ner_tagger(text)\n",
    "pd.DataFrame(outputs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631291</td>\n",
       "      <td>335</td>\n",
       "      <td>358</td>\n",
       "      <td>an exchange of Megatron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end                   answer\n",
       "0  0.631291    335  358  an exchange of Megatron"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = pipeline(\"question-answering\")\n",
    "question = \"What does the customer want?\"\n",
    "outputs = reader(question=question, context=text)\n",
    "pd.DataFrame([outputs])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bumblebee ordered an Optimus Prime action figure from your online store in\n",
      "Germany. Unfortunately, when I opened the package, I discovered to my horror\n",
      "that I had been sent an action figure of Megatron instead.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "outputs = summarizer(text, max_length=45, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sehr geehrter Amazon, letzte Woche habe ich eine Optimus Prime Action Figur aus\n",
      "Ihrem Online-Shop in Deutschland bestellt. Leider, als ich das Paket öffnete,\n",
      "entdeckte ich zu meinem Entsetzen, dass ich stattdessen eine Action Figur von\n",
      "Megatron geschickt worden war! Als lebenslanger Feind der Decepticons, Ich\n",
      "hoffe, Sie können mein Dilemma verstehen. Um das Problem zu lösen, Ich fordere\n",
      "einen Austausch von Megatron für die Optimus Prime Figur habe ich bestellt.\n",
      "Anbei sind Kopien meiner Aufzeichnungen über diesen Kauf. Ich erwarte, bald von\n",
      "Ihnen zu hören. Aufrichtig, Bumblebee.\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation_en_to_de\", \n",
    "                      model=\"Helsinki-NLP/opus-mt-en-de\")\n",
    "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from transformers import set_seed\n",
    "set_seed(42) # Set the seed to get reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Amazon, last week I ordered an Optimus Prime action figure from your online\n",
      "store in Germany. Unfortunately, when I opened the package, I discovered to my\n",
      "horror that I had been sent an action figure of Megatron instead! As a lifelong\n",
      "enemy of the Decepticons, I hope you can understand my dilemma. To resolve the\n",
      "issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered.\n",
      "Enclosed are copies of my records concerning this purchase. I expect to hear\n",
      "from you soon. Sincerely, Bumblebee.\n",
      "\n",
      "Customer service response:\n",
      "Dear Bumblebee, I am sorry to hear that your order was mixed up. I am satisfied\n",
      "with your purchase. I will gladly see your product and the packaging again\n",
      "before you go out buying at your shop! I'm a small business owner and have not\n",
      "been able to deliver my product to customer before and after an Amazon purchase,\n",
      "so I apologize.\n",
      "\n",
      "Customer service response:\n",
      "\n",
      "All of my orders arrived\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "response = \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\n",
    "prompt = text + \"\\n\\nCustomer service response:\\n\" + response\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hugging Face Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"ecosystem\" width=\"500\" caption=\"An overview of the Hugging Face ecosystem of libraries and the Hub.\" src=\"images/chapter01_hf-ecosystem.png\" id=\"ecosystem\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"hub-overview\" width=\"1000\" caption=\"The models page of the Hugging Face Hub, showing filters on the left and a list of models on the right.\" src=\"images/chapter01_hub-overview.png\" id=\"hub-overview\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"hub-model-card\" width=\"1000\" caption=\"A example model card from the Hugging Face Hub. The inference widget is shown on the right, where you can interact with the model.\" src=\"images/chapter01_hub-model-card.png\" id=\"hub-model-card\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Challenges with Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
